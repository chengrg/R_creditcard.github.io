---
title: "6690_final_project"
author: "Rui Cheng"
date: "12/5/2020"
output: pdf_document
---

```{r}
```

```{r}
library(caret)
library(e1071)
library(corrplot)
library(dplyr)
library("ggplot2")
library(MASS)
library(lattice)
library(ROCR)
library(RWeka)
library(kernlab)
#library(VGAM)
```


## Data Preprocessing

### Load dataset

```{r}
all_data = read.csv("DefaultCreditCard.csv", header=T, na.string=",")
all_data$default.payment.next.month <- as.factor(all_data$default.payment.next.month)
# summary(all_data)

# check for missing data
sum(is.na(all_data))

# drop ID column
all_data = all_data[, 2:25]

# change class labels to text
levels(all_data$default.payment.next.month)[levels(all_data$default.payment.next.month)=="0"] <- "NotDefault"
levels(all_data$default.payment.next.month)[levels(all_data$default.payment.next.month)=="1"] <- "Default"
```

### Encode categorical features

```{r}
# column indices of categorical/numerical features
cat_features_idx <- c(2:4, 6:11)
num_features_idx <- c(1, 5, 12:23)

# set categorical columns to factor type
all_data[,cat_features_idx] <- lapply(all_data[,cat_features_idx], factor)

# one-hot encoding of categorical features
dmy <- dummyVars(" ~ SEX+EDUCATION+MARRIAGE+PAY_0+PAY_2+PAY_3+PAY_4+PAY_5+PAY_6", data = all_data)
onehot_encoded <- predict(dmy, newdata = all_data)

# combine all columns
all_data <- cbind(all_data[,num_features_idx], onehot_encoded, DEFAULT=all_data[,24])


# temp
names(all_data)[names(all_data) == "default.payment.next.month"] <- "DEFAULT"

# summary(all_data)
dim(all_data)
```


### Train/Test split

```{r}
set.seed(42)

# train test split
train_index <- createDataPartition(all_data$DEFAULT, p=0.80, list=FALSE)
train_data <- all_data[train_index, ]
test_data <- all_data[-train_index, ]
# summary(train_data)
dim(train_data)
dim(test_data)


```


### Normalize numerical features

```{r}
# # normalize train data
# train_params <- preProcess(train_data[,c(1:14)], method=c("range"))
# print(train_params)
# train_data[,c(1:14)] <- predict(train_params, train_data[,c(1:14)])
# # summary(train_data)
# 
# # normalize test data
# test_params <- preProcess(test_data[,c(1:14)], method=c("range"))
# print(test_params)
# test_data[,c(1:14)] <- predict(test_params, test_data[,c(1:14)])
# # summary(test_data)
```


### PCA

```{r}
# check constant columns
# names(Filter(function(x)(length(unique(x))==1), train_data))
# remove constant columns
# train_data <- train_data[-c(49, 81)]
# test_data <- test_data[-c(49, 81)]

# transform train data
pca_params_train <- preProcess(train_data, method = c("pca"))
train_data <- predict(pca_params_train, train_data)

# transform test data
# pca_params_test <- preProcess(test_data, method = c("pca"))
test_data <- predict(pca_params_train , test_data)

# keep only the first 20 principle components
train_data <- train_data[, c(2:21, 1)]
test_data <- test_data[, c(2:21, 1)]

# normalize train data
prep <- "standardize"
# prep <- "normalize"
if (prep == "normalize") {
  train_params <- preProcess(train_data, method=c("range"))
  train_data <- predict(train_params, train_data)
  test_params <- preProcess(test_data, method=c("range"))
  test_data <- predict(test_params, test_data)
} else {
  train_params <- preProcess(train_data, method=c("center", "scale"))
  train_data <- predict(train_params, train_data)
  test_params <- preProcess(test_data, method=c("center", "scale"))
  test_data <- predict(test_params, test_data)
}

```



## Data Analysis

### Correlation

```{r}
raw_data = read.csv("DefaultCreditCard.csv", header=T, na.string=",")
raw_data = raw_data[, 2:25]

# plot correlation matrix as heatmap
corr_matrix <- cor(raw_data)
corrplot(corr_matrix, method = "circle")

```


## Helper Functions

### Sorting Smoothing Method

```{r}
# function for calculating and plotting result of Sorting Smoothing Method (SSM)
SSMPlot <- function(y_pred_prob, y_true, n, model_name){
  # convert true labels to numeric
  levels(y_true) <- c(0, 1)
  y_true <- as.numeric(as.character(y_true))
  
  # combine predicted probs and true labels then sort on probs
  combined <- data.frame(cbind(y_pred_prob, y_true))
  sorted <- combined[order(combined$y_pred_prob),]
  
  # compute estimated real probabilities using SSM
  ssm_prob <- c()
  for (i in 1:nrow(sorted)) {
    # get start and end indices for averaging
    start <- ifelse(i-n > 0, i-n, 1)
    end <- ifelse(i+n > nrow(sorted), nrow(sorted), i+n)
    
    # take average of y_true
    p <- sum(sorted$y_true[start:end]) / (2*n + 1)
    
    # append to list
    ssm_prob <- c(ssm_prob, p)
  }
  
  # combine ssm_prob with dataframe
  result_df <- cbind(sorted, ssm_prob)
  
  # show scatterplot
  plot(result_df$y_pred_prob, result_df$ssm_prob, xlim=c(0,1), ylim=c(0,1), main=paste0("SSM Plot - ", model_name), xlab="Predicted Probability", ylab="Actual Probability")
  # show linear regression line
  lr <- lm(result_df$ssm_prob~result_df$y_pred_prob)
  summary(lr)
  abline(lr, col="red")
  # show linear regression line equation and R^2 on plot
  cf <- round(coef(lr), 2)
  eq <- paste0("y = ", 
               ifelse(sign(cf[2])==1, " + ", " - "), abs(cf[2]), " x ",
               ifelse(sign(cf[1])==1, " + ", " - "), abs(cf[1]))
  r_sq <- paste0("R-squared = ", round(summary(lr)$r.squared, 2))
  mtext(eq, 3, line = -2)
  mtext(r_sq, 3, line = -3)
}

```

### Lift Chart and Area Ratio

```{r}
require(ROCR)
LCPlot <- function(y_pred_prob, y_true, model_name) {
  # convert true labels to numeric
  levels(y_true) <- c(0, 1)
  y_true <- as.numeric(as.character(y_true))
  # get performance of model
  y_pred_rocr <- prediction(y_pred_prob, y_true)
  y_perf <- performance(y_pred_rocr, "tpr", "rpp")
  # plot lift chart
  plot(y_perf, main=paste0("Lift Chart - ", model_name), col="red", lwd=1)
  # add baseline curve
  lines(x=c(0, 1), y=c(0, 1), type="l", col="darkgreen", lwd=1)
  # add theoretical best curve
  lines(x=c(0, 0.2212, 1), y=c(0, 1, 1), col="darkblue", lwd=1)
  
  # get AUC value
  auc <- performance(y_pred_rocr, "auc")
  # calculate area ratio
  ar <- (auc@y.values[[1]] - 0.5) / 0.5
  print(paste("The Area Ratio of", model_name, "is:", ar))
}

```


## Models

```{r}
# set training control
train_control <- trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = twoClassSummary)
# metric = "Accuracy"
metric = "ROC"

test_data <- train_data
```


#1. K-nearest neighbor classifiers(KNN)

```{r}
# build the model 
knn_model = train(DEFAULT ~ ., 
                  data = train_data, 
                  method = "knn", 
                  metric = metric,
                  trControl = train_control)
summary(knn_model)

# predict
knn_pred <- predict(knn_model, newdata = test_data)

# confusion matrix
confusionMatrix(knn_pred, test_data$DEFAULT)
```


```{r}
# predict probabilities
knn_pred_prob <- predict(knn_model, test_data, type="prob")
# plot lift chart
LCPlot(knn_pred_prob[,2], test_data$DEFAULT, "K-nearest neighbor")
# SSM plot
SSMPlot(knn_pred_prob[,2], test_data$DEFAULT, 50, "K-nearest neighbor")
```


#2. Logistic Regression (LR)

```{r}
# build the model 
lr_model = glm(DEFAULT ~ .,
               family = binomial(link='logit'), 
               data = train_data)
 
# make prediction
lr_pred <- predict(lr_model, type = 'response', newdata = test_data)
lr_pred <- ifelse(lr_pred > 0.5, 1, 0)

# confusion matrix
lr_pred_factor <- as.factor(lr_pred)
levels(lr_pred_factor)[levels(lr_pred_factor)=="0"] <- "NotDefault"
levels(lr_pred_factor)[levels(lr_pred_factor)=="1"] <- "Default"
confusionMatrix(lr_pred_factor, test_data$DEFAULT)

```



```{r}
# predict probabilities
lr_pred_prob <- predict(lr_model, test_data, type = "response")
# plot lift chart
LCPlot(lr_pred_prob, test_data$DEFAULT, "Logistic Regression")
# SSM plot
SSMPlot(lr_pred_prob, test_data$DEFAULT, 50, "Logistic Regression")
```



#3. Linear Discriminant Analysis(DA)

```{r}
# build the model
lda.fit <- lda(DEFAULT ~ ., data = train_data)
lda.fit
plot(lda.fit)
```

```{r}
# make prediction
lda.pred=predict(lda.fit, test_data)
names(lda.pred)
# Model accuracy
lda.class=lda.pred$class
# confusion matrix
# table(lda.class, test_data_lda$DEFAULT)
confusionMatrix(lda.class, test_data$DEFAULT)
```



```{r}
# predict probabilities
lda_pred_prob <- predict(lda.fit, test_data, type = "prob")
# plot lift chart
LCPlot(lda_pred_prob["posterior"][[1]][,2], test_data$DEFAULT, "Linear Discriminant Analysis")
# SSM plot
SSMPlot(lda_pred_prob["posterior"][[1]][,2], test_data$DEFAULT, 50, "Linear Discriminant Analysis")

```



#4. Neural Network Classifier

```{r}
# train NN model
nn_model = train(DEFAULT~., 
                 data = train_data, 
                 method = "nnet", 
                 metric = metric,
                 trControl = train_control, 
                 verbose = FALSE)

# predict test data
nn_pred <- predict(nn_model, newdata = test_data)

# confusion matrix
confusionMatrix(nn_pred, test_data$DEFAULT)

```


```{r}
# predict probabilities
nn_pred_prob <- predict(nn_model, test_data, type="prob")
# plot lift chart
LCPlot(nn_pred_prob[,2], test_data$DEFAULT, "Neural Network")
# SSM plot
SSMPlot(nn_pred_prob[,2], test_data$DEFAULT, 50, "Neural Network")

```



#5. Naive Bayes Classifier (DO NOT USE)

```{r}
# # train NB model
# nb_model <- naiveBayes(DEFAULT ~ ., data = train_data)
# 
# # model summary
# # nb_model
# 
# # predict test data
# nb_pred <- predict(nb_model, newdata = test_data)
# 
# # confusion matrix
# confusionMatrix(nb_pred, test_data$DEFAULT)
```

```{r}
# predict probabilities
# nb_pred_prob <- predict(nb_model, newdata = test_data, type = "raw")
# # plot lift chart
# LCPlot(nb_pred_prob[,2], test_data$DEFAULT, "Naive Bayes")
# # SSM plot
# SSMPlot(nb_pred_prob[,2], test_data$DEFAULT, 50, "Naive Bayes")

```




#5a. Naive Bayes using caret

```{r}
# build the model
nb_caret_model = train(DEFAULT~., 
                   data = train_data, 
                   method = "naive_bayes", 
                   metric = metric,
                   trControl = train_control)
# summary(dnn_model)
```

```{r}
# make prediction
pred_nbCaret = predict(nb_caret_model, test_data)
# confusion matrix
confusionMatrix(pred_nbCaret, test_data$DEFAULT)
```

```{r}
# predict probabilities
nbCaret_pred_prob <- predict(nb_caret_model, test_data, type = "prob")
# plot lift chart
LCPlot(nbCaret_pred_prob[,2], test_data$DEFAULT, "Naive Bayes")
# SSM plot
SSMPlot(nbCaret_pred_prob[,2], test_data$DEFAULT, 50, "Naive Bayes")

```



#6. C4.5 Decision tree (CT)

```{r}
# build the model
dt_model <- J48(DEFAULT~., data=train_data)
# summary(dt_model)
# plot(dt_model)
```

```{r}
# make prediction
pred_dt <- predict(dt_model, test_data)
# confusion matrix
# table(pred_dt$class, test.data$DEFAULT)
# moan(lda.class==test.data$DEFAULT)
confusionMatrix(pred_dt, test_data$DEFAULT)

```


```{r}
# predict probabilities
dt_pred_prob <- predict(dt_model, test_data, type = "prob")
# plot lift chart
LCPlot(dt_pred_prob[,2], test_data$DEFAULT, "Classification Tree")
# SSM plot
SSMPlot(dt_pred_prob[,2], test_data$DEFAULT, 50, "Classification tree")
```


## Other methods we propose by ourselves
#7. Support Vector Machine(SVM)

```{r}
# remove columns with only 1 unique value
# train_data_svm <- train_data[-c(49, 81)]
# test_data_svm <- test_data[-c(49, 81)]
# build the model
svm_model = train(DEFAULT~., 
                  data = train_data, 
                  method = "svmRadial", 
                  metric = metric,
                  trControl = train_control,
                  trace = FALSE)

summary(svm_model)
```


```{r}
# make prediction
pred_svm = predict(svm_model, test_data)
# confusion matrix
confusionMatrix(pred_svm, test_data$DEFAULT)
```


```{r}
# predict probabilities
svm_pred_prob <-  predict(svm_model, test_data, type = "prob")
# plot lift chart
LCPlot(svm_pred_prob[,2], test_data$DEFAULT, "Support Vector Machine")
# SSM plot
SSMPlot(svm_pred_prob[,2], test_data$DEFAULT, 50, "Support Vector Machine")
```



#8. Deep Neural Network

```{r}
# build the model
dnn_model = train(DEFAULT~., 
                   data = train_data, 
                   method = "dnn", 
                   metric = metric,
                   trControl = train_control)
# summary(dnn_model)
```

```{r}
# make prediction
pred_dnn = predict(dnn_model, test_data)
# confusion matrix
confusionMatrix(pred_dnn, test_data$DEFAULT)
```

```{r}
# predict probabilities
dnn_pred_prob <- predict(dnn_model, test_data, type = "prob")
# plot lift chart
LCPlot(dnn_pred_prob[,2], test_data$DEFAULT, "Deep Neural Network")
# SSM plot
SSMPlot(dnn_pred_prob[,2], test_data$DEFAULT, 50, "Deep Neural Network")

```

#8a. Quadratic Discriminant Analysis

```{r}
# build the model
qda_model = train(DEFAULT~., 
                   data = train_data, 
                   method = "qda", 
                   metric = metric,
                   trControl = train_control)
# summary(qda_model)
```

```{r}
# make prediction
pred_qda = predict(qda_model, test_data)
# confusion matrix
confusionMatrix(pred_qda, test_data$DEFAULT)
```

```{r}
# predict probabilities
qda_pred_prob <- predict(qda_model, test_data, type = "prob")
# plot lift chart
LCPlot(qda_pred_prob[,2], test_data$DEFAULT, "Quadratic Discriminant Analysis")
# SSM plot
SSMPlot(qda_pred_prob[,2], test_data$DEFAULT, 50, "Quadratic Discriminant Analysis")

```




#9. Random Forest

```{r}
# build the model
rf_model = train(DEFAULT~., 
                   data = train_data, 
                   method = "rf", 
                   metric = metric,
                   trControl = train_control)
summary(rf_model)
```

```{r}
# make prediction
pred_rf = predict(rf_model, test_data)
# confusion matrix
confusionMatrix(pred_rf, test_data$DEFAULT)
```

```{r}
# predict probabilities
rf_pred_prob <- predict(rf_model, test_data, type="prob")
# plot lift chart
LCPlot(rf_pred_prob[,2], test_data$DEFAULT, "Random Forest")
# SSM plot
SSMPlot(rf_pred_prob[,2], test_data$DEFAULT, 50, "Random Forest")

```



SVM, boosted tree, bagged tree, random forest, quadratic DA (qda), generalized additive model (gam, gamboost), adaboost trees (adaboost)